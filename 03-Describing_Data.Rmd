# Describing Data {#DescribingData}

:::quote
Average a left-hander with a right-hander and what do you get?<br>
`r tufte::quote_footer('--- Donald Norman, *The Design of Everyday Things* (1988)')`
:::

:::source
This chapter is adapted from Matthew Crump's **Descriptive Statistics** chapter in "Answering Questions with Data." https://www.crumplab.com/statistics/
:::

This chapter is about **descriptive statistics**. These are tools for summarizing data. Some things to keep in mind as we go along are:

  1. Describing data is necessary. Usually, we have way more information than we can process without summarizing into smaller, bite-sized chunks.
  2. There are lots of different ways we can describe data.
  3. There is more than one "correct" way to describe data, and you get to choose which description is most useful--depending on what kind of information you're describing.

  
## Too Many Numbers

UNBOUND Gravel is an annual gravel bike race through the Flint Hills of Kansas. Each year, thousands of cyclists visit Emporia, Kansas. Business owners and community leaders might want to know more about who is visiting their town, so that they can plan accordingly. Knowing the ages of the people traveling to Emporia for the UNBOUND Gravel might help the city plan events that are appropriate and exciting for that age group. So, let's say we know the ages of all the people registered to participate in the UNBOUND Gravel next year. The data might look something like this:

```{r 2toomany,echo=F}
library(truncnorm)
gravel<-rtruncnorm(500,15,80,40,15)
knitr::kable(matrix(round(gravel),ncol=10,nrow=50))
```

Now, what are we going to with that big pile of numbers? Look at it all day long? When we're working with real data, we will have so many numbers that looking at the full dataset will be overwhelming. That is why we need ways to describe the data in a manageable fashion.



```{r gravelIMG, echo=F, fig.cap='The UNBOUND Gravel brings thousands of visitors to Emporia each year. How can we describe this large group of people? <a href="https://www.flickr.com/photos/39814691@N04/7456247184">"The Dirty Kanza 200"</a> by <a href="https://www.flickr.com/photos/39814691@N04">TravelKS</a> is licensed under <a href="https://creativecommons.org/licenses/by-nc-nd/2.0/?ref=ccsearch&atype=html">CC BY-NC-ND 2.0</a>.'}
knitr::include_graphics("img/3/gravel.jpg")
```

The complete description of the data is always the data itself. **Descriptive statistics** and other tools for describing data go one step further to summarize aspects of the data. Summaries are a way to compress the important bits of something down to a useful and manageable tidbit. It's like telling your friends why they should watch a movie: you don't replay the entire movie for them---instead you hit the highlights. Summarizing the data is kinda like a movie review, only for data. We're going to discuss the highlights of the data, not each individual data point.

:::def
**descriptive statistics**: statistics that summarize lots of observations (data sets) into a single, interpretable number. Measures of central tendency and variability (e.g., mean, standard deviation) are examples of descriptives.
:::

## Visualize the Data

We already tried one way of looking at the numbers, and it wasn't useful. Let's try some other ways of looking at the numbers, using graphs. As they say, a picture is worth a thousand data points. We'll take a more thorough look into data visualization in Chapter X. For now, suffice it to say that pictures can help us understand important qualities of our data.

<!-- fix Chapter reference -->

### Plotting Dots

Let's turn all of the numbers into dots, then show them in a graph. Note, when we do this, we have not yet summarized anything about the data. Instead, we're just looking at all of the data in a visual format, rather than looking at the numbers. 

```{r 2gravelPlot, echo=F, fig.cap="Ages of 500 simulated UNBOUND Gravel participants"}
plot(gravel)
```

Figure \@ref(fig:2gravelPlot) displays the same information as that long list of numbers above. This type of graph is a **scatterplot**--the dots are scattered across the plot. Each dot represents the age of one hypothetical (simulated) UNBOUND Gravel participant. The graph has two axes. The horizontal **x-axis**, going from left to right, is labeled "Index". The vertical **y-axis**, going up and down, is labeled "gravel". Before we talk about what we can and cannot see about the data, it is worth mentioning that the way you plot the data will make some things easier to see and some things harder to see. So, what can we now see about the data?

There are lots of dots everywhere. It looks like there are 500 of them because the index goes to 500. It looks like some dots go as high as 70 (or even higher!) and as low as about 20. It looks like there are more dots in the middle-ish area of the plot, sort of spread out around 40ish. 

:::point
We can see all the numbers at once by putting them into a plot. Plotting our data can help us make some preliminary assumptions about our data.
:::

OK, so if these dots represent the ages of 500 people, what can we say about those people? First, the dots are kind of all over the place, so---of course---different people have different ages. But are there any trends? Is the UNBOUND Gravel bringing mostly old people to Emporia? Young people? Middle aged? Children? Centenarians? It's hard to see that exactly in the graph, so let's look at our data a few different ways.

### Grouping Data

Next, let's display our data in a **frequency distribution**. This is one of the simplest ways to display lots of data. Behind the scenes, we'll organize our data into **bins**---smaller subsets. Each bin spans a smaller range within the larger data set. 

:::def
**frequency distribution**: a list, table or graph that displays the frequency of data points within a data set.
:::

:::def
**bin**: smaller subsets of the larger data set. Note that all bins should encompass equal ranges. Bins are sometimes called **intervals**, **classes**, or **buckets**.
:::

Below is a frequency distribution of our UNBOUND Gravel data, organized into bins of 10.

```{r gravelFreq, echo=F}
bins <- seq(10,80,by=10)
gravelBins <- cut(gravel, bins)
knitr::kable(transform(table(gravelBins)), col.names= c("Bin", "Frequency"), "pipe", caption="Frequency distribution of simulated UNBOUND Gravel data")
```

In the frequency distribution above, the `Bin` column tells us the range of each bin. Note that round brackets---`(` and `)`---denote that the bin is inclusive of that number, whereas square brackets---`[` and `]`---denote that the bin is not inclusive of that number. So the first bin includes all scores from 10 to 20, including 10 but not 20. Specifically, the first bin includes cyclists who are 10, 11, 12, 13, 14, 15, 16, 17, 18, and 19 years old. The next bin includes all cyclists in their 20s (ages 20-29), and so on.

The `Frequency` column tells us how many scores in our data set fall within each bin. In other words, it tells us how many cyclists were in their teens, 20s, and so on.

You can choose any bin size that makes sense for your data. I've arbitrarily chosen a bin size of 10 for this data because we naturally talk about people as being "in their 20s" or "in their 30s"---so it makes logical sense. If you were working with income data, it might make more sense to use bin sizes of $10,000.

There are at least two benefits of making a frequency distribution:

1. We can quickly skim this distribution to see approximately which bins are most common. For this specific example, we can quickly see that most people are in their 30s and 40s.

2. We can use the frequency distribution to easily create a visual depiction of the data---a **histogram**.

### Histograms

Making a **histogram** will be our first act of officially summarizing something about the data. We will no longer look at the individual bits of data, instead we will see how the numbers group together. Let's look at a histogram of the UNBOUND Gravel data, and then explain it.

```{r 2gravelHist, echo=F, fig.cap="A histogram of the ages of simulated UNBOUND Gravel participants"}
hist(gravel, breaks=7)
axis(side=1, at=seq(10,80,10), labels=seq(10,80,10), outer=FALSE)
```

The dots and numbers have disappeared, and now we see some bars. Each bar is a summary of the dots, representing the number of dots (frequency count) inside a particular range of ages. Those ranges, listed on the x-axis, are our bins. For example, how many participants were between ages 40 and 50? The sixth bar, the one between 40 and 50 on the x-axis, tells you how many. Look how tall that bar is. How tall is it? The height is shown on the y-axis, which provides a **frequency** count. The frequency is simply the number of people who fall within that particular bin. It looks like around 130 or so cyclists are in their 40s. Does that match up with the frequency distribution in Table \@ref(tab:gravelFreq)? (If I have coded this book correctly, it does!)

Furthermore, you can see that each bin across the x-axis of the histogram corresponds to each bin from the frequency distribution. Bin \#1 goes from 10 to 19, and includes all the cyclists whose age falls within that range (i.e., all the teenagers). Bin \#2 goes from 20 to 29, and so on until the last bin. To make the histogram, we just count up the number of data points falling inside each bin, then plot those frequency counts as a function of the bins. In other words, we make a frequency distribution, and then plot each bin as a bar. Voila, a histogram.

:::def
**histogram**: visual plot of the frequencies (counts) of a single variable. The labels of each bar on the x-axis tell the range of each bin, and the height of each bar on the y-axis tells the frequency of data points in each bin.
:::

What does the histogram help us see about the data? First, we can see the **shape** of data. The shape of the histogram refers to how it goes up and down. The shape tells us where the data is. For example, when the bars are low we know there isn't much data there. When the bars are high, we know there is more data there. So, where is most of the data? It looks like it's mostly in the middle two bins, between 30 and 50. We can also see the **range** of the data. This tells us the minimums and the maximums of the data. There is no data below 10, so we know the youngest person is at least 10 years old; there is also no data larger 80, so we know the oldest person is in their 70s.

When you make a histogram you get to choose how wide each bar will be. For example, below are four different histograms of the very same UNBOUND Gravel data. What changes is the width of the bins. 


```{r 2manyhistbin, echo=FALSE, fig.cap="Four histograms of the same data using different bin widths"}

library(ggplot2)
library(ggpubr)

g1 <- qplot(x=gravel, color="white", bins=2)+
  theme_classic()+
  theme(legend.position="none")

g2 <- qplot(x=gravel, color="white", bins=5)+
  theme_classic()+
  theme(legend.position="none")

g3 <- qplot(x=gravel, color="white", bins=10)+
  theme_classic()+
  theme(legend.position="none")

g4 <- qplot(x=gravel, color="white", bins=15)+
  theme_classic()+
  theme(legend.position="none")

ggarrange(g1, g2, g3, g4, ncol=2, nrow=2)

```

All of the histograms have roughly the same overall shape: From left to right, the bars start off small, then go up, then get small again. In other words, as the numbers get closer to 40-something, they start to occur more frequently. We see this general trend across all the histograms. But, some aspects of the trend fall apart when the bars get really narrow. For example, although the bars generally get taller when moving from 10 to 40, there are some exceptions and the bars seem to fluctuate a little bit. When the bars are wider, there are less exceptions to the general trend. How wide or narrow should your histogram be? It's a Goldilocks question. Make it just right for your data.

## Important Ideas: Distribution, Central Tendency, and Variance

Let's introduce three important ideas that we will use frequently: **distribution**, **central tendency**, and **variance**. These terms are similar to their everyday meanings (although I suspect most people don't say "central tendency" very often).

### Distribution

When you order something from Amazon, where does it come from, and how does it get to your place? That stuff comes from one of Amazon's distribution centers. They distribute all sorts of things by spreading them around to our doorsteps. "To distribute" is to spread something. Notice the data in the histogram is distributed---or spread---across the bins. We can also talk about a distribution as a noun. The histogram is a distribution of the frequency counts across the bins. Distributions are *very, very, very, very, very* important. They can have many different shapes. They can *describe* data, like in the histogram above. And as we will learn in later chapters, they can *produce* data. Many times we will be asking questions about where our data came from, and this usually means asking what kind of distribution could have created our data (more on that later).

:::point
All data occur in a distribution. The shape of that distribution becomes important for the kinds of assumptions we can make about our data.
:::

#### Normal and Non-Normal Distributions

We need to take a quick peek at the normal distribution before we move on. The normal distribution is symmetrical and has most of the data points close to the middle. Here's a visual example:

```{r distributions, echo=FALSE, fig.cap="Normal distribution"}
x <- seq(-4, 4, length=200)
y <- dnorm(x, mean=0, sd=1)
plot(x, y, type="l", lwd=2, xaxt="n", yaxt="n")
```

Two important qualities of the normal distribution are:

1. The middle is very clearly the middle.
2. It is symmetrical---meaning the distribution of scores is equal on the left and right side.

Of course, our data don't always follow such a conveniently shaped distribution. Instead, data could be right-skewed or left-skewed.

***Right-skewed*** or ***positively-skewed*** distributions occur when most of the data are clustered at the lower end of the scale. This clustering makes the tail on the right side of the histogram longer. It is sometimes called positively-skewed because the numbers in that tail are the larger (i.e., more positive) numbers of the distribution.

You might come across right-skewed distributions of data in various fields. These are common in biological and medical fields. One quick example is the distribution of costs of medical care [@Malehi2015]. There are a few procedures or services that might cost upwards of hundreds of thousands of dollars, but the majority of healthcare services do not. These data points might be considered ***outliers***: they are pretty far away from most of the other data points. In other words, there are a few services that extend the right-hand tail of the distribution. So, the distribution might (hypothetically) look something like this:

```{r rightdistributions, echo=FALSE, fig.cap="A right-skewed (or positively-skewed) distribution. Note that, although most of the data are bunched up in the middle-ish, there are a few outliers on the right-hand side of the graph."}

 N <- 10000
 x <- rnbinom(N, 10, .5)
 hist(x, 
 xlim=c(min(x),max(x)), probability=T, nclass=max(x)-min(x)+1, 
   col='lightblue', xlab='x', ylab='y', axes=F, main="Right-skewed distribution")
lines(density(x,bw=1), col='black', lwd=3)
```

***Left-skewed*** or ***negatively-skewed*** distributions are essentially the opposite: They occur when most of the data are clustered around the upper end of the scale. Thus, the left-hand side of the distribution has a longer tail. A practical example of a negatively-skewed variable is age at retirement. Most people retire in their late 60s, but a few lucky (rich!) people might get to retire in their 50s or even 40s! Those few rich 40-something retirees would be outliers, falling in the lower tail. Thus, the distribution is skewed toward the lower end of the scale. A left-skewed distribution might look something like this:


```{r leftdistributions, echo=FALSE, fig.cap="A left-skewed (or negatively-skewed) distribution. Note that, although most of the data are bunched up in the middle-ish, there are a few outliers on the left-hand side of the graph."}

N <- 10000
x <- rhyper(N, 1000, 30, 100)
hist(x, 
     xlim=c(min(x),max(x)), probability=T, nclass=max(x)-min(x)+1, 
     col='lightblue',
     main='Left-skewed distribution',
     axes=F,xlab="x", ylab="y")
lines(density(x,bw=1), col='black', lwd=3)
```

:::question
What are some other variables that might occur in a skewed distribution?
:::

### Central Tendency 

Central tendency is all about sameness: What is common about some numbers? For example, is there anything similar about all of the numbers in \@ref(fig:2gravelHist)? Yes, we can say that most of them are near 40. There is a tendency for most of the numbers to be centered near 40. Notice we are being cautious about our generalization about the numbers. We are not saying they are all 40---indeed they are not. We are saying there is a tendency for many of them to be *around 40*. There are lots of ways to talk about the central tendency of data. There can even be more than one kind of central tendency. For example, if lots of the numbers were around 30, and a similar large amount of numbers were grouped around 50, we could say there were two centers.

### **Variability** 

Variability is all about differentness: What is different about some numbers? For example, is there anything different about all of the numbers in the histogram? Yes, of course! The numbers are not all the same! When the numbers are not all the same, they must vary. So, the variability in the numbers refers to how the numbers are different. How far away are the data points from each other? Are they mostly pretty close, pretty far spread out, something in between? There are many ways to summarize the amount of variability in the numbers, and we discuss these very soon.

## Measures of Central Tendency (Sameness)

We've seen that we can get a sense of data by plotting dots in a graph, and by making a histogram. These tools show us what the numbers look like, approximately how big and small they are, and how similar and different they are from another. It is good to get a feeling about the numbers in this way. But, these visual sensitudes are not very precise. In addition to summarizing numbers with graphs, we can summarize numbers using numbers.

> E pluribus, unum.

Measures of central tendency have one important summary goal: to reduce a pile of numbers to a single number that we can look at. We already know that looking at thousands of numbers is hopeless. Wouldn't it be nice if we could just look at one number instead? We think so. It turns out there are lots of ways to do this. So, if you ever need to describe *most* of the data in a distribution---whether that is simulated ages of cyclists, or income of your hometown, or health measures of geriatric patients, or reading improvement scores of your students, or whatever---you can simply say "Most of the data is around…" some single measurement.

But, just like in Indiana Jones and the Last Crusade, you must choose your measure of central tendency wisely. 

### Mean

The first measure of central tendency we'll discuss is the one that is most commonly reported: the mean. The **mean** is also called the average. You probably already know how to calculate an average. It's the sum of the numbers, divided by the number of numbers.

In short, the formula can be written:

$\overline{x} = \frac{\sum{x}}{N}$

"Great, now I have to learn Greek letters, too?" Yes! Let's break the formula down:

* $\overline{x}$ is the mathematical notation for "mean of x." It's pronounced "x bar." In fact, anything with a bar over it just denotes "average of" that thing.
* $\sum$ is the Greek letter **sigma** and is the mathematical operator for summation. It just tells us to add up all the things that follow it. so, $\sum{x}$ tells us to "sum up all the X values." 
* $N$ on the denominator of the fraction tells us to divide by $N$, or the **number** of data points.

In plain English, the formula looks like:

$mean = \frac{\text{Sum of my numbers}}{\text{Count of my numbers}}$

Let's work through a very simple example. Here's a set of numbers.

> 3 7 9 2 6

1. Add em up: $3+7+9+2+6 = 27$

2. Count em up. We have 5 data points.

3. Divide em: $\frac{27}{5}=5.4$

So, for this data set, $\overline{x}=5.4$.

#### Explaining the Math (optional but fun)

Mathematically, the mean is explained as follows. Assume we have some variable that takes on several values. The math shorthand for this is ${x_1, x_2, x_3, ..., x_n}$. The x's and numbers are just labels for the various data points we observed. We have $n$ number of data points, so our x values go up to $x_n$.

The arithmetic formula for mean is:

$\overline{x} = \frac{\sum_{i=1}^{n} x_{i}}{N}$

You might sometimes see it written as:

$\overline{x} = \frac{1}{2}{\sum\limits_{i=1}^n x_i}$

The formula is telling us the following steps:

* $\sum$ tells us we need to sum up a bunch of numbers. Which ones?
* ${i=1}$ tells us to start at data point \#1.
* $n$ tells us to keep going until we to data point $n$ (that is, the last data point we have, $x_n$).
* $x_i$ tells us where we're looking. We're looking at the values for the variable X, and we're looking to start at the 1st x value (i.e., $x_{i=1}$)

Wikipedia has pretty straightforward explanations of [capital-sigma summation notation](https://en.wikipedia.org/wiki/Summation#Capital-sigma_notation) and of [notation in probability and statistics](https://en.wikipedia.org/wiki/Notation_in_probability_and_statistics) if you are interested.

"That looks like Greek to me". Yup. The $\sum$ symbol is called **sigma**, and it stands for the operation of summing (adding). The little "i" on the bottom, and the little "n" on the top refers to all of the numbers in the set, from the first number "i" to the last number "n". The letters are just arbitrary labels, called **variables** that we use for descriptive purposes. The $x_{i}$ refers to individual numbers in the set. We sum up all of the numbers, then divide the sum by $N$, which is the total number of numbers. Because it is implied that $i_{1}$ and that we will keep summing until we've summed all the numbers, you will sometimes see those elements ($n$ and $i=1$) omitted the formula. Sometimes you will see $\overline{x}$ to refer to the mean of all of the numbers.

Here's a recap of our mean example from above:

> 3 7 9 2 6

* Add em up: $3+7+9+2+6 = 27$
* Count em up: $i_{1}$ = 3, $i_{2}$ = 7, $i_{3}$ = 9, $i_{4}$ = 2, $i_{5}$ = 6; N=5, because $i$ went from 1 to 5
* Divide em: $mean = 27 / 5 = 5.4$

Or, to put the numbers in the formula, it looks like this:

$Mean = \overline{X} = \frac{\sum_{i=1}^{n} x_{i}}{N} = \frac{3+7+9+2+6}{5} = \frac{27}{5} = 5.4$

#### What's in a Name? (optional, probably)

I have somewhat arbitrarily decided to use the symbol $\overline{x}$ to represent the term **mean** in this chapter. I've done that because, in my experience, this is one of the more common ways to represent the sample mean in statistics. You might also see it labeled $\overline{X}$ (same "bar" but with an uppercase X instead of lowercase). You might also see it labeled as $M$. Truthfully, $M$ is my preferred way to express the mean, because that's how we'll be reporting the mean in our written work.

OK fine, that is how to compute the mean. But, like we imagined, you probably already knew that, and if you didn't that's OK, now you do. What's next?

Is the mean a good measure of central tendency? By now, you should know: it depends. 

#### What Does It ***Mean***? (optional, probably)

It is not enough to know the formula for the mean, or to be able to use the formula to compute a mean for a set of numbers. We believe in your ability to add and divide numbers. What you really need to know is what the mean really "means". This requires that you know what the mean does, and not just how to do it. Puzzled? Let's explain.

Can you answer this question: What happens when you divide a sum of numbers by the number of numbers? What are the consequences of doing this? What is the formula doing? What kind of properties does the result give us? FYI, the answer is not that we compute the mean.

OK, so what happens when you divide any number by another number? Of course, the key word here is divide. We literally carve the number up top in the numerator into pieces. How many times do we split the top number? That depends on the bottom number in the denominator. Watch:

$\frac{12}{3} = 4$

So, we know the answer is 4. But, what is really going on here is that we are slicing and dicing up 12 aren't we. Yes, and we slicing 12 into three parts. It turns out the size of those three parts is 4. So, now we are thinking of 12 as three different pieces $12 = 4 + 4 + 4$. I know this will be obvious, but what kind of properties do our pieces have? You mean the fours? Yup. Well, obviously they are all fours. Yes. The pieces are all the same size. They are all equal. So, division equalizes the numerator by the denominator...

"Umm, I think I learned this in elementary school, what does this have to do with the mean?". The number on top of the formula for the mean is just another numerator being divided by a denominator isn't it. In this case, the numerator is a sum of all the values in your data. What if it was the sum of all of the 500 happiness ratings? The sum of all of them would just be a single number adding up all the different ratings. If we split the sum up into equal parts representing one part for each person's happiness what would we get? We would get 500 identical and equal numbers for each person. It would be like taking all of the happiness in the world, then dividing it up equally, then to be fair, giving back the same equal amount of happiness to everyone in the world. This would make some people more happy than they were before, and some people less happy right. Of course, that's because it would be equalizing the distribution of happiness for everybody. This process of equalization by dividing something into equal parts is what the **mean** does. See, it's more than just a formula. It's an idea. This is just the beginning of thinking about these kinds of ideas. We will come back to this idea about the mean, and other ideas, in later chapters.

> Pro tip: The mean is the one and only number that can take the place of every number in the data, such that when you add up all the equal parts, you get back the original sum of the data.

### Mode

The **mode** is the most frequently occurring number in your measurement. That is it. How do you find it? You have to count the number of times each number appears in your measure. Whichever one occurs most frequently is the mode.

Take this set of data for example:

> 1 1 1 2 3 4 5 6

The mode of the above set is 1, which occurs three times. Every other number only occurs once.

OK fine. What happens here:

> 1 1 1 2 2 2 3 4 5 6

Hmm, now 1 and 2 both occur three times each. What do we do? We say there are two modes, and they are 1 and 2.

Why is the mode a measure of central tendency? When we ask, "what are my numbers like?", we can say, "most of the number are like a 1." (Or whatever the mode happens to be.)

Is the mode a good measure of central tendency? That depends on your data. For example, imagine that each number represented a category instead of a score. Maybe the data reflects student majors, and you want to know what major "most" students are. Turning the numbers into categories might make the data look like this:

> Psychology Psychology Psychology Nursing Nursing Nursing Biology Education Business Art

Obviously, it does not make sense to calculate a mean of these numbers anymore. (In this case, $\overline{x}=2.7$, which means... what? That the average major is somewhere between Nursing and Biology? No, that doesn't make sense.) Instead, we figure out the mode(s) of the data. In this case, the modes are Psychology and Nursing. So most students are either a psych major or a nursing major. This helps us understand our data.

Switching gears a bit, consider these numbers:

> 1 1 2 3 4 5 6 7 8 9

Here, the mode is 1, because there are two 1s, and all of the other numbers occur once. But, are most of the numbers like a 1? No, they are mostly not 1s. Although the mode can certainly be useful---especially when we are dealing with categorical variables---it is not always the most informative measure of central tendency.

:::point
When you have categories or other nominal data, the **mode** is a good measure of central tendency.
:::

### Median

The **median** is the exact middle of the data. After all, we are asking about central tendency, so why not go to the center of the data and see where we are. What do you mean middle of the data? Let's look at these numbers:

> 1 5 4 3 6 7 9

Umm, OK. So, three is in the middle? Isn't that kind of arbitrary? Yes. Before we can compute the median, we need to order the numbers from smallest to largest.

> 1 3 4 **5** 6 7 9

Now, 5 is in the middle. And, by middle we mean in the middle. There are three numbers to the left of 5, and three numbers to the right. So, 5 is definitely in the middle.

OK fine, but what happens when there aren't an even number of numbers? Then the middle will be missing right? Let's see:

> 1 2 3 4 5 6

There is no number between 3 and 4 in the data, the middle is empty. In this case, we compute the median by figuring out the number in between 3 and 4. So, the median would be 3.5.

Is the median a good measure of central tendency? Sure, it is often very useful. One property of the median is that it stays in the middle even when some of the other numbers get really weird. For example, consider these numbers:

> 1 2 3 4 4 4 **5** 6 6 6 7 7 1000

Most of these numbers are smallish, but the 1000 is a big old weird number (an **outlier**), very different from the rest. The median is still 5, because it is in the middle of these ordered numbers. We can also see that five is pretty similar to most of the numbers (except for 1000). So, the median does a pretty good job of representing most of the numbers in the set, and it does so even if one or two of the numbers are very different from the others.

What happens if we take the mean of that same dataset, with that score of 1000 still in there? I'll do the math for you: $\overline{x}=81.15$. Is 81 a good description of most of the data in this set? Not really, right? As you can see, the mean is sensitive to outliers. Including that outlier score of 1000 dramatically increases the mean. But, including that outlier score of 1000 does not really affect the median. A median of 5 is still a reasonable way to describe most of the data.

:::point
When you have outliers in your data, the **median** is a safe measure of central tendency to report.
:::



### All together now

Just to remind ourselves of the mode, median, and mean, take a look at the next histogram. We have overlaid the location of the mean (red), median (green), and mode (blue). For this dataset, the three measures of central tendency all give different answers. The mean is the largest because it is influenced by large numbers, even if they occur rarely. The mode and median are insensitive to large numbers that occur infrequently, so they have smaller values.

```{r 2meanmodemed, echo=FALSE, fig.cap="A histogram with the mean (red), the median (green), and the mode (blue)."}
my_mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

exp_num<-round(rexp(1000,.15),digits=1)

qplot(exp_num, binwidth=5, col=I("grey"), fill=I("white"))+
  geom_vline(xintercept=mean(exp_num), color="red", size=1.5)+
  geom_vline(xintercept=median(exp_num), color="green", size=1.5)+
  geom_vline(xintercept=my_mode(exp_num), color="blue", size=1.5)+
  theme_classic()

```

:::question
Which measure of central tendency would you report for the data in Figure \@ref(fig:2meanmodemed) above? What are the limitations of reporting just the mean?
:::

## Measures of Variation (Differentness)

What did you do when you wrote essays in high school about a book you read? Probably compare and contrast something right? When you summarize data, you do the same thing. Measures of central tendency give us something like comparing does: they tell us stuff about what is the same. Measures of variation give us something like contrasting does: they tell us stuff about what is different.

First, we note that whenever you see a bunch of numbers that aren't the same, you already know there are some differences. This means the numbers vary, and there is variation in the size of the numbers.

### Range

Consider these 10 numbers, that I already ordered from smallest to largest for you:

> 1 3 4 5 5 6 7 8 9 24

The numbers have variation, because they are not all the same. We can use the range to describe the width of the variation. The range refers to the **minimum** (smallest value) and **maximum** (largest value) in the set. So, the range would be 1 and 24.

The range is a good way to quickly summarize the boundaries of your data in just two numbers. By computing the range we know that none of the data is larger or smaller than the range. And, it can alert you to outliers. For example, if you are expecting your numbers to be between 1 and 7, but you find the range is 1 - 340,500, then you know you have some big numbers that shouldn't be there, and then you can try to figure out why those numbers occurred (and potentially remove them if something went wrong).

### Difference Scores

It would be nice to summarize the amount of differentness in the data. Here's why. If you thought that raw data (lots of numbers) is too big to look at, then you will be frightened to contemplate how many differences there are to look at. For example, these 10 numbers are easy to look at:

> 1 3 4 5 5 6 7 8 9 24

But, what about the difference between the numbers, what do those look like? We can compute the difference scores between each number, then put them in a matrix like the one below:

```{r 2diffscores,echo=F}
numbers<-c(1, 3, 4, 5, 5, 6, 7, 8, 9, 24)
mat<-matrix(rep(numbers,10),ncol=10)
differences<-t(mat)-numbers
row.names(differences)<-numbers
colnames(differences)<-numbers
knitr::kable(differences,row.names=T)

```

We are looking at all of the possible differences between each number and every other number. So, in the top left, the difference between 1 and itself is 0. One column over to the right, the difference between 3 and 1 (3-1) is 2, etc. As you can see, this is a 10×10 matrix, which means there are 100 differences to look at. Not too bad, but if we had 500 numbers, then we would have 500*500 = 250,000 differences to look at (go for it if you like looking at that sort of thing). 

Pause for a simple question. What would this matrix look like if all of the 10 numbers in our data were the same number? It should look like a bunch of 0s right? Good. In that case, we could easily see that the numbers have no variation.

But, when the numbers are different, we can see that there is a very large matrix of difference scores. How can we summarize that? How about we apply what we learned from the previous section on measures of central tendency. We have a lot of differences, so we could ask something like, what is the average difference that we have? So, we could just take all of our differences, and compute the mean difference right? What do you think would happen if we did that?

Let's try it out on these three numbers:

> 1 2 3

```{r 2diffscoreSmall,echo=F}
numbers<-c(1, 2,3)
mat<-matrix(rep(numbers,3),ncol=3)
differences<-t(mat)-numbers
row.names(differences)<-numbers
colnames(differences)<-numbers
knitr::kable(differences, row.names=T)
```

You might already guess what is going to happen. Let's compute the mean:

$\text{mean of difference scores} = \frac{0+1+2-1+0+1-2-1+0}{9} = \frac{0}{9} = 0$

Uh oh, we get zero for the mean of the difference scores. This will always happen whenever you take the mean of the difference scores. We can see that there are some differences between the numbers, so using 0 as the summary value for the variation in the numbers doesn't make much sense.

Furthermore, you might also notice that the matrices of difference scores are redundant. The diagonal is always zero, and numbers on one side of the diagonal are the same as the numbers on the other side, except their signs are reversed. So, that's one reason why the difference scores add up to zero.

These are little problems that can be solved by computing the **variance** and the **standard deviation**. For now, the standard deviation is a just a trick that we use to avoid getting a zero. But, later we will see it has properties that are important for other reasons.

### Variance

Variability, variation, variance, vary, variable, varying, variety. Confused yet? Before we describe the **variance**, we want to you be OK with how this word is used. First, don't forget the big picture. We know that variability and variation refers to the big idea of differences between numbers. We can even use the word variance in the same way. When numbers are different, they have variance. 

The word **variance** also refers to a specific summary statistic, the sum of the squared deviations from the mean. Let's see the formula in English first:

$variance = \frac{\text{Sum of squared difference scores}}{\text{Number of Scores}}$

The formulas for variance and standard deviation depend on whether you think your data represents an entire population of numbers, or is sample from the population. We discuss this issue in later on. For now, we divide by N, later we discuss why you will often divide by N-1 instead.


#### Deviations from the Mean

We got a little bit complicated before when we computed the difference scores between all of the numbers in the data. Let's do it again, but in a more manageable way. This time, we calculate the difference between each score and the mean. The idea here is

1. We can figure out how similar our scores are by computing the mean
2. Then we can figure out how different our scores are from the mean

This could tell us

1. Something about whether our scores are really all very close to the mean (which could help us know if the mean is good representative number of the data)
2. Something about how much differences there are in the numbers

Take a look at this table:

```{r 2deviations,echo=F, message=F,warning=F}
library(dplyr)
scores<-1:6
values<-c(1,6,4,2,6,8)
mean_scores<-mean(values)
Difference_from_Mean<-values-mean_scores
the_df<-data.frame(scores,values,mean=rep(mean_scores,6),Difference_from_Mean)

the_df <- the_df %>%
  rbind(c("Sums",colSums(the_df[1:6,2:4]))) %>%
  rbind(c("Means",colMeans(the_df[1:6,2:4])))
knitr::kable(the_df)

```

The first column shows we have 6 scores in the data set, and the `value` columns shows each score. The sum of the values, and the mean is presented on the last two rows. The sum and the mean were obtained by:

$\frac{1+6+4+2+6+8}{6} = \frac{27}{6} = 4.5$. 

The third column `mean`, appears a bit silly. We are just listing the mean once for every score. If you think back to our discussion about the meaning of the mean, then you will remember that it equally distributes the total sum across each data point. We can see that here, if we treat each score as the mean, then every score is a 4.5. We can also see that adding up all of the means for each score gives us back 27, which is the sum of the original values. Also, we see that if we find the mean of the mean scores, we get back the mean (4.5 again).

All of the action is occurring in the fourth column, `Difference_from_Mean`. Here, we are showing the difference scores from the mean, using $x_{i}-\overline{x}$. In other words, we subtracted the mean from each score. So, the first score, 1, is -3.5 from the mean, the second score, 6, is +1.5 from the mean, and so on.

Now, we can look at our original scores and we can look at their differences from the mean. Notice, we don't have a matrix of raw difference scores, so it is much easier to see. But we still have a problem:

We can see that there are non-zero values in the difference scores, so we know there are a differences in the data. But, when we add them all up, we still get zero, which makes it seem like there are a total of zero differences in the data. Why does this happen?? What can we do about it?

#### Balancing Point

One brief pause here to point out another wonderful property of the mean. It is the balancing point in the data. If you take a pen or pencil and try to balance it on your figure so it lays flat what are you doing? You need to find the center of mass in the pen, so that half of it is on one side, and the other half is on the other side. That's how balancing works. One side = the other side. 

We can think of data as having mass or weight to it. If we put our data on our bathroom scale, we could figure out how heavy it was by summing it up. If we wanted to split the data down the middle so that half of the weight was equal to the other half, then we could balance the data on top of a pin. The mean of the data tells you where to put the pin. It is the location in the data, where the numbers on the one side add up to the same sum as the numbers on the other side.

If we think this through, it means that the sum of the difference scores from the mean will always add up to zero. This is because the numbers on one side of the mean will always add up to -x (whatever the sum of those numbers is), and the numbers of the other side of the mean will always add up to +x (which will be the same value only positive). And:

$-x + x = 0$, right? 

Right.

#### Squared Deviations

Some devious someone divined a solution to the fact that differences scores from the mean always add to zero. Can you think of any solutions? For example, what could you do to the difference scores so that you could add them up, and they would weigh something useful, that is they would not be zero?

The devious solution is to square the numbers. Squaring numbers converts all the negative numbers to positive numbers. For example, $2^2 = 4$, and $-2^2 = 4$. Remember how squaring works, we multiply the number twice: $2^2 = 2*2 = 4$, and $-2^2 = -2*-2 = 4$. We use the term **squared deviations** to refer to differences scores that have been squared. Deviations are things that move away from something. The difference scores move away from the mean, so we also call them **deviations**.

Let's look at our table again, but add the squared deviations.

```{r 2deviationssquared,echo=F}
scores<-1:6
values<-c(1,6,4,2,6,8)
mean_scores<-mean(values)
Difference_from_Mean<-values-mean_scores
Squared_Deviations <- Difference_from_Mean^2
the_df<-data.frame(scores,values,mean=rep(mean_scores,6),Difference_from_Mean,Squared_Deviations)

the_df <- the_df %>%
  rbind(c("Sums",colSums(the_df[1:6,2:5]))) %>%
  rbind(c("Means",colMeans(the_df[1:6,2:5])))
knitr::kable(the_df)

```

OK, now we have a new column called `squared_deviations`. These are just the difference scores squared. So, $-3.5^2 = 12.25$, etc. You can confirm for yourself with your cell phone calculator.

Now that all of the squared deviations are positive, we can add them up. When we do this we create something very special called the **sum of squares** (SS), also known as the sum of the squared deviations from the mean. We will talk at length about this SS later on. So, when you get there, remember that you already know what it is, just some sums of some squared deviations, nothing fancy.

#### Variance (for real this time)

Guess what, we already computed the variance. It already happened, and maybe you didn't notice.

First, see if you can remember what we are trying to do here. Take a pause, and see if you can tell yourself what problem we are trying solve.

> pause

We are trying to get a summary of the differences in our data. There are just as many difference scores from the mean as there are data points, which can be a lot, so it would be nice to have a single number to look at. Something like a mean would tell us about the average differences in the data.

If you look at the table, you can see we already computed the mean of the squared deviations. First, we found the sum (SS), then below that we calculated the mean = 5.916 repeating. This is the **variance**. The variance is the mean of the sum of the squared deviations:

$variance = \frac{SS}{N}$, where SS is the sum of the squared deviations, and N is the number of observations.

OK, now what. What do I do with the variance? What does this number mean? Good question. The variance is often an unhelpful number to look at. Why? Because it is not in the same scale as the original data. This is because we squared the difference scores before taking the mean. Squaring produces large numbers. For example, we see a 12.25 in there. That's a big difference, bigger than any difference between any two original values. What to do? How can we bring the numbers back down to their original unsquared size?

If you are thinking about taking the square root, that's a ding ding ding, correct answer for you. We can always unsquare anything by taking the square root. So, let's do that to 5.916. $\sqrt{5.916} =$ `r sqrt(5.916)`.

### Standard Deviation

Oops, we did it again. We already computed the standard deviation, and we didn't tell you. The standard deviation is the square root of the variance... At least, it is right now, until we complicate matters for you in the next chapter.

Here is the formula for the standard deviation:

$\text{standard deviation} = \sqrt{Variance} = \sqrt{\frac{SS}{N}}$.

We could also expand this to say:

$\text{standard deviation} = \sqrt{\frac{\sum_{i}^{n}({x_{i}-\bar{x})^2}}{N}}$


Don't let those big square root signs put you off. Now, you know what they are doing there. Just bringing our measure of the variance back down to the original size of the data. Let's look at our table again:

```{r,echo=F}
scores<-1:6
values<-c(1,6,4,2,6,8)
mean_scores<-mean(values)
Difference_from_Mean<-values-mean_scores
Squared_Deviations <- Difference_from_Mean^2
the_df<-data.frame(scores,values,mean=rep(mean_scores,6),Difference_from_Mean,Squared_Deviations)

the_df <- the_df %>%
  rbind(c("Sums",colSums(the_df[1:6,2:5]))) %>%
  rbind(c("Means",colMeans(the_df[1:6,2:5])))
knitr::kable(the_df)

```

We measured the standard deviation as `r sqrt(5.916)`. Notice this number fits right in the with differences scores from the mean. All of the scores are kind of in and around + or - `r sqrt(5.916)`. Whereas, if we looked at the variance, 5.916 is just too big, it doesn't summarize the actual differences very well.

What does all this mean? Well, if someone told they had some number with a mean of 4.5 (like the values in our table), and a standard deviation of `r sqrt(5.916)`, you would get a pretty good summary of the numbers. You would know that many of the numbers are around 4.5, and you would know that not all of the numbers are 4.5. You would know that the numbers spread around 4.5. You also know that the spread isn't super huge, it's only + or - `r sqrt(5.916)` on average. That's a good starting point for describing numbers. 

If you had loads of numbers, you could reduce them down to the mean and the standard deviation, and still be pretty well off in terms of getting a sense of those numbers.

## Creating Your Own Descriptive Statistics?

We spent many paragraphs talking about variation in numbers, and how to use calculate the **variance** and **standard deviation** to summarize the average differences between numbers in a data set. The basic process was to 1) calculate some measure of the differences, then 2) average the differences to create a summary. We found that we couldn't average the raw difference scores, because we would always get a zero. So, we squared the differences from the mean, then averaged the squared differences differences. Finally, we square rooted our measure to bring the summary back down to the scale of the original numbers. 

Perhaps you haven't heard, but there is more than one way to skin a cat, but we prefer to think of this in terms of petting cats, because some of us love cats. Jokes aside, perhaps you were also thinking that the problem of summing differences scores (so that they don't equal zero), can be solved in more than one way. Can you think of a different way, besides squaring?

### Absolute deviations

How about just taking the absolute value of the difference scores. Remember, the absolute value converts any number to a positive value. Check out the following table:

```{r 2absolute,echo=F}
scores<-1:6
values<-c(1,6,4,2,6,8)
mean_scores<-mean(values)
Difference_from_Mean<-values-mean_scores
Absolute_Deviations <- abs(Difference_from_Mean)
the_df<-data.frame(scores,values,mean=rep(mean_scores,6),Difference_from_Mean,Absolute_Deviations)

the_df <- the_df %>%
  rbind(c("Sums",colSums(the_df[1:6,2:5]))) %>%
  rbind(c("Means",colMeans(the_df[1:6,2:5])))
knitr::kable(the_df)

```

This works pretty well too. By converting the difference scores from the mean to positive values, we can now add them up and get a non-zero value (if there are differences). Then, we can find the mean of the sum of the absolute deviations. If we were to map the terms sum of squares (SS), variance and standard deviation onto these new measures based off of the absolute deviation, how would the mapping go? For example, what value in the table corresponds to the SS? That would be the sum of absolute deviations in the last column. How about the variance and standard deviation, what do those correspond to? Remember that the variance is mean ($SS/N$), and the standard deviation is a square-rooted mean ($\sqrt{SS/N}$). In the table above we only have one corresponding mean, the mean of the sum of the absolute deviations. So, we have a **variance** measure that does not need to be square rooted. We might say the mean absolute deviation, is doing double-duty as a variance and a standard-deviation. Neat.

### Other sign-inverting operations

In principle, we could create lots of different summary statistics for variance that solve the summing to zero problem. For example, we could raise every difference score to any even numbered power beyond 2 (which is the square). We could use, 4, 6, 8, 10, etc. There is an infinity of even numbers, so there is an infinity of possible variance statistics. We could also use odd numbers as powers, and then take their absolute value. Many things are possible. The important aspect to any of this is to have a reason for what you are doing, and to choose a method that works for the data-analysis problem you are trying to solve. Note also, we bring up this general issue because we want you to understand that statistics is a creative exercise. We invent things when we need them, and we use things that have already been invented when they work for the problem at hand.

## Remember to Look at the Data

Descriptive statistics are great and we will use them a lot in the course to describe data. You may suspect that descriptive statistics also have some short-comings. This is very true. They are compressed summaries of large piles of numbers. They will almost always be unable to represent all of the numbers fairly. There are also different kinds of descriptive statistics that you could use, and it sometimes not clear which one's you should use. 

Perhaps the most important thing you can do when using descriptives is to use them in combination with looking at the data in a graph form. This can help you see whether or not your descriptives are doing a good job of representing the data.

### Anscombe's Quartet

To hit this point home, and to get you thinking about the issues we discuss in the next chapter, check this out. It's called Anscombe's Quartet, because these interesting graphs and numbers and numbers were produced by @Anscombe1973. You are looking at pairs of measurements. Each graph has an X and Y axis, and each point represents two measurements. Each of the graphs looks very different, right? 

```{r, echo=FALSE, message=FALSE}
library(data.table)
ac <- fread("data/anscombe.txt")
ac<-as.data.frame(ac)

ac_long<-data.frame(x=c(ac[,1],
                        ac[,3],
                        ac[,5],
                        ac[,7]),
                    y=c(ac[,2],
                        ac[,4],
                        ac[,6],
                        ac[,8]),
                    quartet = as.factor(rep(1:4,each=11))
                        )

ggplot(ac_long, aes(x=x, y=y, color=quartet))+
  geom_point()+
  theme_classic()+
  facet_wrap(~quartet)


```


Well, would you be surprised if I told that the descriptive statistics for the numbers in these graphs are exactly the same? It turns out they do have the same descriptive statistics. In the table below I present the mean and variance for the x-values in each graph, and the mean and the variance for the y-values in each graph.


```{r echo=FALSE}
library(dplyr)

ac_long_summary <- ac_long %>%
                    dplyr::group_by(quartet) %>%
                    dplyr::summarise(mean_of_x = mean(x),
                              var_of_x = var(x),
                              mean_of_y = mean(y),
                              var_of_y = var(y))

knitr::kable(ac_long_summary)

```


The descriptives are all the same! Anscombe put these special numbers together to illustrate the point of graphing your numbers. If you only look at your descriptives, you don't know what patterns in the data they are hiding. If you look at the graph, then you can get a better understanding.


## Videos

### Measures of center: Mode

<iframe width="560" height="315" src="https://www.youtube.com/embed/hQ2p-QQpGso" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

### Measures of center: Median and Mean

<iframe width="560" height="315" src="https://www.youtube.com/embed/BopmCXCjq08" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

### Standard deviation part I

<iframe width="560" height="315" src="https://www.youtube.com/embed/8Yguf93s5dI" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

### Standard deviation part II

<iframe width="560" height="315" src="https://www.youtube.com/embed/KodmsOXScBc" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>





